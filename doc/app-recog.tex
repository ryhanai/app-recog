\documentclass[11pt]{jarticle}
\setlength{\topmargin}{-15mm}
\setlength{\evensidemargin}{-2mm}
\setlength{\oddsidemargin}{3mm}
\setlength{\textheight}{24.5cm}
\setlength{\textwidth}{15cm}
%%
\usepackage[dvipdfm]{graphicx}
\usepackage{enumerate}

\usepackage{subfigure}

\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{bm} % 数式の中のBold (\bm{})
\usepackage{amsmath} % 数式の中の改行 (\begin{gather} \\ )

\usepackage{listings,jlisting}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\newcommand {\figref}[1] {図\ref{#1}}
\newcommand{\tabref}[1] {表\ref{#1}}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}

\renewcommand{\subfigtopskip}{1pt}
\renewcommand{\subfigbottomskip}{1pt}
\renewcommand{\subfigcapskip}{1pt}
\setlength{\floatsep}{6pt}           % 図表と図表の間のマージン
\setlength{\dblfloatsep}{6pt}        % ↑の二段組 version
\setlength{\textfloatsep}{6pt}       % 図表と本文の間のマージン
\setlength{\abovecaptionskip}{-2pt}   % 図表の caption と図表本体の間のマージン
\setlength{\belowcaptionskip}{2pt}   % 図表の caption 下部のマージン

\input amssym.def

\author{東京大学　情報理工学系研究科　稲葉研究室}
\title{エッジベース二次元対象物認識モジュール(AppRecog)}
%\date{2010/4/10}

\begin{document}
\setlength{\baselineskip}{1.5zw}

\maketitle

%\tableofcontents

\section{概要}

画像から二次元的に対象物を認識，その位置，姿勢およびスケールを出力するモジュールです．
通常，カメラ出力共通I/Fで画像および，カメラパラメータを出力するカメラモ
ジュールと組み合わせて利用します．

http://openrtm.org/openrtm/ja/project/NEDO\_Intelligent\_PRJ\_HiroAccPrj\_5002

\section{ダウンロードとコンパイル}

https://code.google.com/p/app-recog/
からダウンロードします．
\begin{lstlisting}
 $ tar xvfz AppRecog-0.1.0.tgz
 $ cd app-recog
 $ make
\end{lstlisting}

\section{開発・動作環境}

\begin{itemize}
 \item Ubuntu Linux 10.04 LTS
 \item OpenRTM-aist 1.0.0-RELEASE C++版
 \item OpenCV 2.3
\end{itemize}
 OpenCVのバージョンに注意してください．

\section{インタフェース}

\begin{itemize}
 \item データポート
       \begin{itemize}
	\item 入力: Img::TimedCameraImage (Img.idl) \\
	      画像出力共通インタフェース準拠のカメラモジュールから，
	      画像及び，カメラパラメータを受取ります．
	\item 出力: TimedRecognitionResult (Vision.idl) \\
	      認識結果共通インタフェースにしたがい，対象物体の位置姿勢を出力します．
	      Img::TimedCameraImage 処理結果を画像として出力します．
       \end{itemize}
 \item サービスポート \\
       認識対象のモデルを設定するために使います．
       あらかじめ．ModelFiles/ModelList.txtにモデルIDとモデル定義ファイ
       ル名を記述し，モデルIDを引数としてサービスコールを行います．
       setModelID(i)は，i番のモデルを使用することを意味します．
\end{itemize}
 認識結果はTimedRecognitionResultによって出力されます．
 具体的な出力内容は以下の通りです．現在，対象物の姿勢以外は入っていま
 せん．
\begin{verbatim}
  0: 0, 1: 0, 2: 0, 3: 0, 4: 0
  5: 0, 6: 0, 7: 0, 
  8: R00,  9: R01, 10: R02, 11: Tx
 12: R10, 13: R11, 14: R12, 15: Ty
 16: R20, 17: R21, 18: R22, 19: Tz
\end{verbatim}

\section{詳細説明}

与えられたモデルと，画像から抽出したエッジのChamferマッチングにより類似度を
評価します．そして，粒子群最適化により類似度が最大の位置，姿勢，スケール
を出力します．
連続的に送られてくる画像に対して認識を行いますが，認識結果の時間方向の連続性
は考慮せず，各フレームで一番尤度が高い位置を計算し，その尤度が閾値以上で
あれば検出結果を返します．指定した閾値以下の場合は，認識結果は出力しませ
ん．

% 閾値の意味について
% サービスによる認識対象の切り替え
% 認識モジュールにおける対象物モデルの定義の仕方

モデルと実画像のマッチングは，画像上で行われます．検出した位置，姿勢，ス
ケールからカメラパラメータを用いて，カメラ座標系における対象物の位
置，姿勢が計算されます．
カメラパラメータはデータポートを通して画像と一緒に送られてくるも
のを使用します．正しいカメラパラメータが入っていない場合も対象物の検出
はできますが，出力される結果は正確ではありません．
画像座標での$(x,y,\theta, s)$の探索範囲，検出の閾値は，
コンフィグファイルAppRecog.confで指定できます．
また，モデル定義ファイルはModelFileディレクトリの中に置き，ファイルは頂
点と辺によって表現されるエッジと，円からなります．

\begin{figure}[tb]
 \begin{center}
  \includegraphics[width=0.8\linewidth]{figure/apprecog.png}
  \caption{認識例}
  \label{fig:apprecog}
 \end{center}
\end{figure}

\section{実行およびテスト}

まず，画像をキャプチャするモジュールを用意します．

  \subsection{カメラ共通I/F準拠の画像キャプチャモジュール(CameraComp)}

  以下のwebから，大阪大学により開発され画像キャプチャモジュール
  CameraCompをダウンロード，コンパイルします．ログ画像によるテストを行う
  ため，LoadPictureCompモジュールも同様にダウンロードします．

  http://www-arailab.sys.es.osaka-u.ac.jp/CameraIF/

  \subsection{接続}

  実際にカメラモジュールと接続し，オンラインでテストを行います．
  このときのモジュール接続は\figref{fig:test_by_camera}のようになり，
  実行手順は，以下の通りです．
  \begin{enumerate}
   \item 認識モジュールAppRecogとキャプチャモジュールをそれぞれ実行
   \item rtshellで画像の入出力を接続(system editor上で操作してもよい)
   \item 2つのRTCをactivate
  \end{enumerate}

  \begin{lstlisting}
   $ cd CameraComp
   $ ./CaptureCameraComp
   別端末で
   $ cd app-recog/
   $ build/bin/AppRecogComp
   別端末で（rtctreeでのパスは適当に補完する）
   $ rtcon CaptureCamera0.rtc:CameraImage AppRecog0.rtc:InputImage
   $ rtact CaptureCamera0.rtc AppRecog0.rtc
  \end{lstlisting}

  初期設定で認識範囲のスケールが絞ってあるため，認識できない場合は
  対象物までの距離をいろいろ変えてみてください．
  また，背景に模様がなく，対象物と異なる色のものを置くと認識しやすくなり
  ます．

  テストとして，カメラモジュールをLoadPictureCompモジュールに差し替え，
  あらかじめ撮っておいた画像を用いてテストを行う場合，
  CaptureCameraCompをLoadPictureCompに置き換えた接続となります．
  ログ画像の指定は，LoadPictureCompモジュールのLoadPicture.confで
  行う．AppRecogモジュール付属の画像data/parts4.jpgを用いて確認してくだ
  さい．

  LoadPicture.confで読み込む画像を指定するには，rtc.confに
\begin{verbatim}
Processing Module.LoadPicture.config_file: LoadPicture.conf
\end{verbatim}
を，LoadPicture.confに
\begin{verbatim}
conf.default.string_file_name: parts4.jpg
\end{verbatim}
と記述します．parts4.jpgは読込みたいファイルの名前を書きます．
正しく動作していれば，\figref{fig:apprecog}（左）のようなウィンドウが表
示されます．

\begin{figure}[tb]
 \begin{center}
  \includegraphics[width=0.8\linewidth]{figure/recog_test_cam.png}
  \caption{USBカメラを用いたテスト}
  \label{fig:test_by_camera}
 \end{center}
\end{figure}


% \addcontentsline{toc}{chapter}{参考文献}
% \markboth{参考文献}{参考文献}
% \bibliographystyle{junsrt}
% \bibliography{p2009}

\end{document}
